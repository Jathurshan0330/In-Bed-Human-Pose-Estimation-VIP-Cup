# -*- coding: utf-8 -*-
"""LWIR_to_RGB

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qTQDyp1AsFLwQwOsxgLMlaDqtp_ZzRud
"""

import os
import sys
import shutil 
import glob

import numpy as np
import random
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import cv2 as cv


import torch
import torchvision
from time import time
from torchvision import datasets, transforms
from torchvision.io import read_image
from torch import nn, optim
from torch.utils.data import Dataset
print(torch.__version__)

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#cd '/content/drive/MyDrive/In-Bed-Human-Pose-Estimation(VIP-CUP)'

parent_dir_j = "/content/drive/MyDrive/In-Bed-Human-Pose-Estimation(VIP-CUP)"
parent_dir = "/content/drive/MyDrive/LWIR_to_RGB"
#os.mkdir(parent_dir)

cd '/content/drive/MyDrive/LWIR_to_RGB'

!ls '/content/drive/MyDrive/LWIR_to_RGB'

dirc = "A"
path_lwir = os.path.join(parent_dir,dirc)
#os.mkdir(path_lwir)

dirc = "B"
path_rgb = os.path.join(parent_dir,dirc)
#os.mkdir(path_rgb)

path_lwir_train = os.path.join(path_lwir,"train" )
#os.mkdir(path_lwir_train)

path_lwir_val = os.path.join(path_lwir, "val")
#os.mkdir(path_lwir_val)

path_lwir_test = os.path.join(path_lwir, "test")
#os.mkdir(path_lwir_test)

path_rgb_train = os.path.join(path_rgb, "train")
#os.mkdir(path_rgb_train)

path_rgb_val = os.path.join(path_rgb, "val")
#os.mkdir(path_rgb_val)

path_rgb_test = os.path.join(path_rgb, "test")
#os.mkdir(path_rgb_test)

# Transfering true images to Training data for discriminator RGB in drive

cover_type = 'uncover'
count = 1
for i in range(1,21):
  if i < 10:
      data_name = "0000"+str(i)              
  else:
      data_name = "000"+str(i) 
  
  #Destination path
  if i<=10: 
    destination_lwir = path_lwir_train
    destination_rgb = path_rgb_train
    if i==10:
      print("Moving last subject in Training")
  elif (i>10 and i<=15):
    destination_lwir = path_lwir_val
    destination_rgb = path_rgb_val
    if i==15:
      print("Moving last subject in Val")
  else:
    destination_lwir = path_lwir_test
    destination_rgb = path_rgb_test 
    if i==20:
      print("Moving last subject in Testing")

  for j in range(1,46):
    if j < 10:
        img_name = "00000"+str(j)
    else:
        img_name = "0000"+str(j)  


    #Source LWIR
    source = '/content/drive/MyDrive/In-Bed-Human-Pose-Estimation(VIP-CUP)/train/' + data_name +'/IR/'+cover_type+'/image_'+img_name +'.png'
    #im_ir = cv.imread(source)
    #im_ir = cv.resize(im_ir, (576, 1024), interpolation = cv.INTER_AREA)
    #print(im_ir.shape)
    #cv.imwrite(os.path.join(destination_lwir,str(count)+'.png' ), im_ir)
    shutil.copy(source, destination_lwir)
    os.rename(os.path.join(destination_lwir,'image_'+img_name +'.png' ),os.path.join(destination_lwir,str(count)+'.png' ))
    #count+=1

    #Source RGB
    source = '/content/drive/MyDrive/In-Bed-Human-Pose-Estimation(VIP-CUP)/train/' + data_name +'/RGB/'+cover_type+'/image_'+img_name +'.png'
    im_rgb = cv.imread(source)
    im_rgb = cv.resize(im_rgb, (120,160), interpolation = cv.INTER_AREA)
    #print(im_rgb.shape)
    cv.imwrite(os.path.join(destination_rgb,str(count)+'.png' ), im_rgb)
    #shutil.copy(source, destination_rgb)
    #os.rename(os.path.join(destination_rgb,'image_'+img_name +'.png' ),os.path.join(destination_rgb,str(count)+'.png' ))
    count+=1
    #break
  #break

# # Transfering true images to Training data for discriminator RGB in drive

# cover_type = 'uncover'
# count = 1
# for i in range(1,26):
#   if i < 10:
#       data_name = "0000"+str(i)              
#   else:
#       data_name = "000"+str(i) 
  
#   #Destination path
#   if i<=15: 
#     destination = os.path.join(parent_dir,'train')
#   elif (i>15 and i<=20):
#     destination = os.path.join(parent_dir,'val')
#   else:
#     destination = os.path.join(parent_dir,'test')


#   for j in range(1,46):
#     if j < 10:
#         img_name = "00000"+str(j)
#     else:
#         img_name = "0000"+str(j)  


#     #Source LWIR
#     source_ir = '/content/drive/MyDrive/In-Bed-Human-Pose-Estimation(VIP-CUP)/train/' + data_name +'/IR/'+cover_type+'/image_'+img_name +'.png'
#     im_ir = cv.imread(source_ir)
    
#     #shutil.copy(source, destination_lwir)
#     #os.rename(os.path.join(destination_lwir,'image_'+img_name +'.png' ),os.path.join(destination_lwir,str(count)+'.png' ))
#     #count+=1

#     #Source RGB
#     source_rgb = '/content/drive/MyDrive/In-Bed-Human-Pose-Estimation(VIP-CUP)/train/' + data_name +'/RGB/'+cover_type+'/image_'+img_name +'.png'
#     im_rgb = cv.imread(source_rgb)
#     print(im_ir.shape,im_rgb.shape)

#     im_ir = cv.resize(im_ir, (576, 1024), interpolation = cv.INTER_AREA)
#     #shutil.copy(source, destination_rgb)
#     #os.rename(os.path.join(destination_rgb,'image_'+img_name +'.png' ),os.path.join(destination_rgb,str(count)+'.png' ))
#     print(im_ir.shape,im_rgb.shape)
#     comb = np.concatenate((im_ir , im_rgb ), axis=1)
#     cv.imwrite('out.png', comb)
#     count+=1
#     break
#   break

"""# Install"""

!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix

import os
os.chdir('pytorch-CycleGAN-and-pix2pix/')

!pip install -r requirements.txt

"""# Datasets

Download one of the official datasets with:

-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`

Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets).
"""

!bash ./datasets/download_pix2pix_dataset.sh facades

cd '/content/drive/MyDrive/LWIR_to_RGB/pytorch-CycleGAN-and-pix2pix'

!python datasets/combine_A_and_B.py --fold_A /content/drive/MyDrive/LWIR_to_RGB/A  --fold_B /content/drive/MyDrive/LWIR_to_RGB/B --fold_AB /content/drive/MyDrive/LWIR_to_RGB

"""# Pretrained models

Download one of the official pretrained models with:

-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`

Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`
"""

!bash ./scripts/download_pix2pix_model.sh facades_label2photo

"""# Training

-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`

Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A.
"""

cd '/content/drive/MyDrive/LWIR_to_RGB'

!python /content/drive/MyDrive/LWIR_to_RGB/pytorch-CycleGAN-and-pix2pix/train.py --dataroot /content/drive/MyDrive/LWIR_to_RGB --name lwir_rgb_jat --model pix2pix --direction AtoB  --save_epoch_freq 1000 --n_epochs 100 --n_epochs_decay 300

print(hello)

!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA

"""# Testing

-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`

Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.

> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:
> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.

> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).

> See a list of currently available models at ./scripts/download_pix2pix_model.sh
"""

!ls '/content/drive/MyDrive/LWIR_to_RGB/checkpoints/'

!ls '/content/drive/MyDrive/LWIR_to_RGB/checkpoints/lwir_rgb_jat/'

cd '/content/drive/MyDrive/LWIR_to_RGB/checkpoints/lwir_rgb_jat/'

!python /content/drive/MyDrive/LWIR_to_RGB/pytorch-CycleGAN-and-pix2pix/test.py --dataroot /content/drive/MyDrive/LWIR_to_RGB  --direction AtoB --model pix2pix --name lwir_rgb_jat

"""# Visualize"""

import matplotlib.pyplot as plt

img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')
plt.imshow(img)

img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')
plt.imshow(img)

img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')
plt.imshow(img)

"""#Testing on Covered Data"""

cd '/content/drive/MyDrive/LWIR_to_RGB/checkpoints/lwir_rgb_jat/'

dirc = "A"
path_lwir = os.path.join(parent_dir,dirc)
#os.mkdir(path_lwir)

# Transfering true images to Training data for discriminator RGB in drive

cover_type = 'uncover'
count = 1
for i in range(1,21):
  if i < 10:
      data_name = "0000"+str(i)              
  else:
      data_name = "000"+str(i) 
  
  #Destination path
  if i<=10: 
    destination_lwir = path_lwir_train
    destination_rgb = path_rgb_train
    if i==10:
      print("Moving last subject in Training")
  elif (i>10 and i<=15):
    destination_lwir = path_lwir_val
    destination_rgb = path_rgb_val
    if i==15:
      print("Moving last subject in Val")
  else:
    destination_lwir = path_lwir_test
    destination_rgb = path_rgb_test 
    if i==20:
      print("Moving last subject in Testing")

  for j in range(1,46):
    if j < 10:
        img_name = "00000"+str(j)
    else:
        img_name = "0000"+str(j)  


    #Source LWIR
    source = '/content/drive/MyDrive/In-Bed-Human-Pose-Estimation(VIP-CUP)/train/' + data_name +'/IR/'+cover_type+'/image_'+img_name +'.png'
    #im_ir = cv.imread(source)
    #im_ir = cv.resize(im_ir, (576, 1024), interpolation = cv.INTER_AREA)
    #print(im_ir.shape)
    #cv.imwrite(os.path.join(destination_lwir,str(count)+'.png' ), im_ir)
    shutil.copy(source, destination_lwir)
    os.rename(os.path.join(destination_lwir,'image_'+img_name +'.png' ),os.path.join(destination_lwir,str(count)+'.png' ))
    #count+=1

    #Source RGB
    source = '/content/drive/MyDrive/In-Bed-Human-Pose-Estimation(VIP-CUP)/train/' + data_name +'/RGB/'+cover_type+'/image_'+img_name +'.png'
    im_rgb = cv.imread(source)
    im_rgb = cv.resize(im_rgb, (120,160), interpolation = cv.INTER_AREA)
    #print(im_rgb.shape)
    cv.imwrite(os.path.join(destination_rgb,str(count)+'.png' ), im_rgb)
    #shutil.copy(source, destination_rgb)
    #os.rename(os.path.join(destination_rgb,'image_'+img_name +'.png' ),os.path.join(destination_rgb,str(count)+'.png' ))
    count+=1
    #break
  #break